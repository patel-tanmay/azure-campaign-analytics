{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "75bd817f-9aba-4ab0-bd66-28b6aa542c97",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Rerun this in dashboard notebook\n",
    "storage_account = dbutils.secrets.get(scope=\"local-scope\", key=\"storage-account-name\")\n",
    "client_id = dbutils.secrets.get(scope=\"local-scope\", key=\"sp-client-id\")\n",
    "tenant_id = dbutils.secrets.get(scope=\"local-scope\", key=\"sp-tenant-id\")\n",
    "client_secret = dbutils.secrets.get(scope=\"local-scope\", key=\"sp-client-secret\")\n",
    "\n",
    "spark.conf.set(f\"fs.azure.account.auth.type.{storage_account}.dfs.core.windows.net\", \"OAuth\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth.provider.type.{storage_account}.dfs.core.windows.net\", \n",
    "               \"org.apache.hadoop.fs.azurebfs.oauth2.ClientCredsTokenProvider\")\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.id.{storage_account}.dfs.core.windows.net\", client_id)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.secret.{storage_account}.dfs.core.windows.net\", client_secret)\n",
    "spark.conf.set(f\"fs.azure.account.oauth2.client.endpoint.{storage_account}.dfs.core.windows.net\", \n",
    "               f\"https://login.microsoftonline.com/{tenant_id}/oauth2/token\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1877401d-c85f-4cb3-a9d2-2221dcb8687c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.parquet(f\"abfss://curated@{storage_account}.dfs.core.windows.net/uplift-output/\")\n",
    "df.createOrReplaceTempView(\"uplift_results\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a480bc4e-ddfb-4639-8379-858052e9732c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## üéØ Uplift Modeling Dashboard ‚Äì Criteo Campaign\n",
    "\n",
    "This dashboard summarizes the impact of uplift modeling on Criteo's 1M user dataset.\n",
    "\n",
    "**Goal**: Identify high-value customers who are most likely to respond positively to a targeted campaign ‚Äî _only because they are treated_ (i.e., receive marketing).\n",
    "\n",
    "- Model: XGBoost-based Uplift Regressor (causalML)\n",
    "- Dataset: Criteo 1M (curated & feature engineered)\n",
    "- Outcome: Conversion uplift score per user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1459457e-ebae-46b5-8145-787f3518d1ba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT treatment, COUNT(*) AS users, ROUND(AVG(conversion), 4) AS avg_conversion_rate\n",
    "FROM uplift_results\n",
    "GROUP BY treatment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "644e6197-7265-4d62-b368-dfcd3f55c1c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT \n",
    "  COUNT(*) AS total_users,\n",
    "  ROUND(MIN(uplift_score), 4) AS min_uplift,\n",
    "  ROUND(MAX(uplift_score), 4) AS max_uplift,\n",
    "  ROUND(AVG(uplift_score), 4) AS avg_uplift\n",
    "FROM uplift_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ecc085c-2efa-4c78-be5a-4a5fee41da1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT * \n",
    "FROM uplift_results\n",
    "ORDER BY uplift_score DESC\n",
    "LIMIT 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5c2b3fa-2520-45ad-aa84-7668ed1ea65a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b44c5a49-4534-4884-ae9d-c31a9e382348",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "df = df.withColumn(\"uplift_segment\", when(col(\"uplift_score\") > 0.05, \"High Uplift\")\n",
    "                                     .when(col(\"uplift_score\") > 0.01, \"Medium Uplift\")\n",
    "                                     .otherwise(\"Low/Negative Uplift\"))\n",
    "df.createOrReplaceTempView(\"uplift_results_segmented\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a185eaf9-8563-4849-8aea-50bc0f79b3be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "SELECT uplift_segment, COUNT(*) AS users\n",
    "FROM uplift_results_segmented\n",
    "GROUP BY uplift_segment\n",
    "ORDER BY users DESC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "77d7162f-09e9-4c97-bd04-ac4dcd81029a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### üîê Data Governance & Reproducibility\n",
    "\n",
    "- Data Source: Curated Criteo dataset stored securely in ADLS Gen2\n",
    "- Access Control: Managed via Databricks Secret Scopes and SPNs\n",
    "- Versioning: Model training and artifacts tracked with MLflow\n",
    "- Lineage: Feature engineering and output pipelines documented in Notebooks\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7599292638787589,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "04_Uplift_Model_Dashboard_Presentation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
